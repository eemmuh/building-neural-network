{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18b1865-70bd-457e-84f4-9b7f62300c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976f40d3-5a15-4cdb-97e5-a294604509eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights and biases\n",
    "# assume network has 2 input features, 3 neurons in the hidden layer, and 1 output neuron\n",
    "# He initialization\n",
    "def initialize_parameters(input_dim, hidden_dim, output_dim):\n",
    "    np.random.seed(1)\n",
    "    W1 = np.random.randn(hidden_dim, input_dim) * np.sqrt(2. / input_dim)\n",
    "    b1 = np.zeros((hidden_dim, 1))\n",
    "    W2 = np.random.randn(output_dim, hidden_dim) * np.sqrt(2. / hidden_dim)\n",
    "    b2 = np.zeros((output_dim, 1))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201a2ac0-4717-4379-aff0-cd37b006781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sigmoid function as activation function and its derivative for backpropagation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(A):\n",
    "    return A * (1 - A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2921e6b-bc79-4aad-9f25-75f45a224634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propagation step computes the output of network\n",
    "def forward_propagation(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return A2, A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "008af4f5-6d81-4707-b606-71c431a1d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use binary cross-entropy as our cost function\n",
    "# to prevent overfitting, you can add L2 regularization to the cost function\n",
    "def compute_cost(A2, Y, parameters, lambda_):\n",
    "    m = Y.shape[1]\n",
    "    W1, W2 = parameters\n",
    "    cross_entropy_cost = -np.sum(Y * np.log(A2) + (1 - Y) * np.log(1 - A2)) / m\n",
    "    L2_regularization_cost = (lambda_ / (2 * m)) * (np.sum(np.square(W1)) + np.sum(np.square(W2)))\n",
    "    cost = cross_entropy_cost + L2_regularization_cost\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ed80b3-d17b-4895-adbe-f21690068f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backpropagation computes gradients and updates weights and biases\n",
    "# to prevent overfitting, add L2 regularization to the gradients\n",
    "def backpropagation(X, Y, A2, A1, W1, W2, lambda_):\n",
    "    m = X.shape[1]\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(dZ2, A1.T) / m + (lambda_ / m) * W2\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid_derivative(A1)\n",
    "    dW1 = np.dot(dZ1, X.T) / m + (lambda_ / m) * W1\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "\n",
    "    gradients = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cf7a814-99e8-4d9d-88d6-e4f3c302bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gradient descent to update the weights and biases\n",
    "def update_parameters(parameters, gradients, learning_rate):\n",
    "    W1, b1, W2, b2 = parameters\n",
    "    dW1, db1, dW2, db2 = gradients[\"dW1\"], gradients[\"db1\"], gradients[\"dW2\"], gradients[\"db2\"]\n",
    "\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "    updated_parameters = (W1, b1, W2, b2)\n",
    "    return updated_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78472e42-9a2a-4a81-b820-a1b321328318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize your inputs for better convergence\n",
    "def normalize(X):\n",
    "    mean = np.mean(X, axis=1, keepdims=True)\n",
    "    std = np.std(X, axis=1, keepdims=True)\n",
    "    return (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ffaf7f-a90b-45aa-b3aa-085943ac9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train network\n",
    "# pass lambda for regularization and normalize data\n",
    "def train(X, Y, input_dim, hidden_dim, output_dim, num_iterations, learning_rate, lambda_):\n",
    "    X = normalize(X)\n",
    "    W1, b1, W2, b2 = initialize_parameters(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        A2, A1 = forward_propagation(X, W1, b1, W2, b2)\n",
    "        cost = compute_cost(A2, Y, (W1, W2), lambda_)\n",
    "        gradients = backpropagation(X, Y, A2, A1, W1, W2, lambda_)\n",
    "        parameters = (W1, b1, W2, b2)\n",
    "        updated_parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "        W1, b1, W2, b2 = updated_parameters\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}: cost = {cost}\")\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d93a52-fcd8-4d7c-9674-9c69021bb9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "def predict(X, W1, b1, W2, b2):\n",
    "    X = normalize(X)  # ensure input is normalized\n",
    "    A2, _ = forward_propagation(X, W1, b1, W2, b2)\n",
    "    return A2 > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8afcb3b8-cbff-4d0e-835b-7e31804e38bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: cost = 0.7780487377740158\n",
      "Iteration 100: cost = 0.7501011519837623\n",
      "Iteration 200: cost = 0.7362321743627279\n",
      "Iteration 300: cost = 0.7285526943448185\n",
      "Iteration 400: cost = 0.72358682203027\n",
      "Iteration 500: cost = 0.7198580455171393\n",
      "Iteration 600: cost = 0.7167426648540964\n",
      "Iteration 700: cost = 0.7139720028984724\n",
      "Iteration 800: cost = 0.7114243954086702\n",
      "Iteration 900: cost = 0.7090395809550074\n",
      "Predictions: [[False False  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# example dataset\n",
    "X = np.array([[0, 0, 1, 1], [0, 1, 0, 1]])  # 2 features\n",
    "Y = np.array([[0, 1, 1, 0]])  # Binary output\n",
    "\n",
    "# Define hyperparameters\n",
    "input_dim = 2\n",
    "hidden_dim = 3\n",
    "output_dim = 1\n",
    "num_iterations = 1000\n",
    "learning_rate = 0.01\n",
    "lambda_ = 0.01  # Regularization parameter\n",
    "\n",
    "# Train network\n",
    "W1, b1, W2, b2 = train(X, Y, input_dim, hidden_dim, output_dim, num_iterations, learning_rate, lambda_)\n",
    "\n",
    "# Predict\n",
    "predictions = predict(X, W1, b1, W2, b2)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2044f8cf-ca0e-420c-99a2-9d77e1624284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cost value is decreasing as training progresses, indicating that the model is learning and improving its performance.\n",
    "# A decreasing cost suggests that the model's predictions are getting closer to the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4e7a7-ebbc-4f8c-9da9-fbda67968cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
